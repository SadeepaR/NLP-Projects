{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhofZboeeEQX"
      },
      "source": [
        "## Stemming\n",
        "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqfPlCVf2rdH"
      },
      "source": [
        "*we use stemming as a step of word preprocessing before we convert words in to vectors*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RV4XAF8ReEQY"
      },
      "outputs": [],
      "source": [
        "# ex - we solve a Classification Problem\n",
        "# we need to find out wether comments of product is a positive review or negative review\n",
        "# our data set has text data which are reviews. we need to classify those reviews as positive or negative\n",
        "# Reviews will have words like eating, eat,eaten --> root word / stem word = eat \n",
        "# so instead of all these words we use eat\n",
        "\n",
        "#[going,gone,goes]--->go (go is word stem)\n",
        "\n",
        "#using stemming we can find the stem of the word\n",
        "\n",
        "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlFzSGuHgGh5"
      },
      "source": [
        "Let`s find stem of a word using stemming\n",
        "\n",
        "stemming techniques\n",
        "\n",
        "1) PorterStemmer\n",
        "\n",
        "2) RegexpStemmer\n",
        "\n",
        "3) snowball stemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShtJBRB1eEQZ"
      },
      "source": [
        "\n",
        "\n",
        "### PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rMYuJ1w7eEQZ"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dNHlL_kjeEQa"
      },
      "outputs": [],
      "source": [
        "stemming=PorterStemmer()\n",
        "#create obj from PorterStemmer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b3sF62jeEQa",
        "outputId": "6141613b-867e-4613-f33b-b9b1dc4d2404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "#for each word apply PorterStemming\n",
        "\n",
        "for word in words:\n",
        "    print(word + \"---->\" + stemming.stem(word))\n",
        "\n",
        "#PorterStemmer class has a fun called stem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N0WeEOPhxLY"
      },
      "source": [
        "sometimes when we apply stemming we don`t get correct words, some times after stemming we will get meaningful words.\n",
        "we use lematization to solve those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Lb8n7729eEQa",
        "outputId": "3ddfb64f-0cfa-464b-c8d5-a76b01df6f24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'congratul'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem('congratulations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7SpLK5eaeEQb",
        "outputId": "0f5dbd6b-91c5-4276-a6c4-a8548bef4d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sit'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem(\"sitting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvx22u66eEQb"
      },
      "source": [
        "### RegexpStemmer class\n",
        "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example\n",
        "\n",
        "we can provide regular expression & it will apply regular expression stemming\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KjzdPTGmeEQb"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import RegexpStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SGIH54EOeEQc",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "# RegexpStemmer(regexp, min=0)\n",
        "\n",
        "# A stemmer that uses regular expressions to identify morphological affixes.\n",
        "# Any substrings that match the regular expressions will be removed.\n",
        "\n",
        "# morphological affixes -> regex expression\n",
        "\n",
        "# ing$|s$|e$|able$  --> from words which have last words of ing,s,e,able -> remove those parts\n",
        "# if a word ends with above regx patterns, those patterns will remove from that word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FBWZUxineEQc",
        "outputId": "87f2dfaa-ab3c-4025-c3f8-19e088b8fe2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'eat'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_stemmer.stem('eating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xb2wFKa3eEQc",
        "outputId": "3175f6e2-a9c9-4f5f-e754-eaa1efc673ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ingeat'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_stemmer.stem('ingeating')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrjdP70eEQc"
      },
      "source": [
        "### Snowball Stemmer\n",
        " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEXAg71B1sjk"
      },
      "source": [
        "Snowball stemmer has better accurcy (better formation of words) compared to potter stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hq8F647jeEQc"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jXBfUqzqeEQd"
      },
      "outputs": [],
      "source": [
        "snowballsstemmer=SnowballStemmer('english')\n",
        "# need to specify the language we use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r0p-0HPeEQd",
        "outputId": "c83cd902-af6b-42e7-ff47-6dd95a6c62a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+snowballsstemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNvdySZ92SNB"
      },
      "source": [
        "compare potter stemmer with snowball stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW48P5zieEQd",
        "outputId": "02f638cd-2c1c-4721-f469-ac37b46bbf0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fairli', 'sportingli')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#apply potter stmmer\n",
        "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_PIsJhYeEQd",
        "outputId": "bc519edb-15b8-424a-db75-9c577d9967b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#apply snowball stemmer\n",
        "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7GQVFq8UeEQd",
        "outputId": "d5be34a1-7fb4-48d4-c1b4-f220f6844cfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'goe'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snowballsstemmer.stem('goes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-bB8HQRbeEQe",
        "outputId": "d0b89e70-5fbe-4790-975e-f27c1cfe3eb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'goe'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem('goes')\n",
        "\n",
        "#But both snowball stemmer and potter stemmer did not word corectly for words like 'goes'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJH0FA183RZQ"
      },
      "outputs": [],
      "source": [
        "# For chatBots we can`t use stemming. for that we use lemitization.\n",
        "# lemitization has all the words dictrionary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
